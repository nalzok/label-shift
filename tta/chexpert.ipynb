{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silence WARNING:root:The use of `check_types` is deprecated and does not have any effect.\n",
    "# https://github.com/tensorflow/probability/issues/1523\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "class CheckTypesFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return \"check_types\" not in record.getMessage()\n",
    "\n",
    "\n",
    "logger.addFilter(CheckTypesFilter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 23:33:03.300796: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2022-11-08 23:33:03.333910: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-08 23:33:03.971496: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2022-11-08 23:33:03.971708: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2022-11-08 23:33:03.971721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "import scipy.stats\n",
    "import einops\n",
    "from functools import partial\n",
    "\n",
    "from functools import partial\n",
    "from collections import namedtuple\n",
    "import itertools\n",
    "from itertools import repeat\n",
    "from time import time\n",
    "import chex\n",
    "\n",
    "\n",
    "import jax\n",
    "import jax.random as jr\n",
    "import jax.numpy as jnp\n",
    "from jax import vmap, grad, jit\n",
    "from jax import lax, numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "\n",
    "from flax.core import freeze, unfreeze\n",
    "from flax import linen as nn\n",
    "import flax\n",
    "\n",
    "import jaxopt\n",
    "import optax\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "#jax.config.update(\"jax_enable_x64\", False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0), TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1), TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0), TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1), TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0), TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1), TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0), TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "cpu_count = os.cpu_count()\n",
    "print(cpu_count)\n",
    "\n",
    "# Run jax on multiple CPU cores\n",
    "# https://github.com/google/jax/issues/5506\n",
    "# https://stackoverflow.com/questions/72328521/jax-pmap-with-multi-core-cpu\n",
    "import os \n",
    "#os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=90'\n",
    "\n",
    "import jax\n",
    "print(jax.devices())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kpmurphy/github/label-shift/tta'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tta.utils.Dataset'>\n",
      "<class 'tta.datasets.MultipleDomainDataset'>\n",
      "<class 'tta.datasets.chexpert.MultipleDomainCheXpert'>\n"
     ]
    }
   ],
   "source": [
    "import tta\n",
    "from tta.utils import *\n",
    "print(Dataset)\n",
    "\n",
    "from tta.datasets import *\n",
    "print(MultipleDomainDataset)\n",
    "\n",
    "from tta.datasets.chexpert import *\n",
    "print(MultipleDomainCheXpert)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kpmurphy/github/label-shift/tta'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "root = '/home/kpmurphy/data/CheXpert'\n",
    "root = Path(root)\n",
    "labels = pd.read_csv(root / \"labels.csv\", index_col=\"image_id\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>NO_FINDING</th>\n",
       "      <th>ENLARGED_CARDIOMEDIASTINUM</th>\n",
       "      <th>CARDIOMEGALY</th>\n",
       "      <th>AIRSPACE_OPACITY</th>\n",
       "      <th>LUNG_LESION</th>\n",
       "      <th>PULMONARY_EDEMA</th>\n",
       "      <th>CONSOLIDATION</th>\n",
       "      <th>PNEUMONIA</th>\n",
       "      <th>ATELECTASIS</th>\n",
       "      <th>...</th>\n",
       "      <th>EFFUSION</th>\n",
       "      <th>PLEURAL_OTHER</th>\n",
       "      <th>FRACTURE</th>\n",
       "      <th>SUPPORT_DEVICES</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>split</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>AGE_AT_CXR</th>\n",
       "      <th>PRIMARY_RACE</th>\n",
       "      <th>ETHNICITY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CheXpert-v1.0/train/patient42720/study2/view1_frontal.jpg</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>patient42720</td>\n",
       "      <td>train</td>\n",
       "      <td>Male</td>\n",
       "      <td>58</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic/Non-Latino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CheXpert-v1.0/train/patient42720/study7/view1_frontal.jpg</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>patient42720</td>\n",
       "      <td>train</td>\n",
       "      <td>Male</td>\n",
       "      <td>58</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic/Non-Latino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CheXpert-v1.0/train/patient42720/study8/view1_frontal.jpg</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>patient42720</td>\n",
       "      <td>train</td>\n",
       "      <td>Male</td>\n",
       "      <td>58</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic/Non-Latino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CheXpert-v1.0/train/patient42720/study6/view1_frontal.jpg</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>patient42720</td>\n",
       "      <td>train</td>\n",
       "      <td>Male</td>\n",
       "      <td>58</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic/Non-Latino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CheXpert-v1.0/train/patient42720/study1/view1_frontal.jpg</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>patient42720</td>\n",
       "      <td>train</td>\n",
       "      <td>Male</td>\n",
       "      <td>58</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic/Non-Latino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Unnamed: 0  NO_FINDING  \\\n",
       "image_id                                                                     \n",
       "CheXpert-v1.0/train/patient42720/study2/view1_f...           0           3   \n",
       "CheXpert-v1.0/train/patient42720/study7/view1_f...           1           3   \n",
       "CheXpert-v1.0/train/patient42720/study8/view1_f...           2           3   \n",
       "CheXpert-v1.0/train/patient42720/study6/view1_f...           3           3   \n",
       "CheXpert-v1.0/train/patient42720/study1/view1_f...           4           3   \n",
       "\n",
       "                                                    ENLARGED_CARDIOMEDIASTINUM  \\\n",
       "image_id                                                                         \n",
       "CheXpert-v1.0/train/patient42720/study2/view1_f...                           1   \n",
       "CheXpert-v1.0/train/patient42720/study7/view1_f...                           3   \n",
       "CheXpert-v1.0/train/patient42720/study8/view1_f...                           3   \n",
       "CheXpert-v1.0/train/patient42720/study6/view1_f...                           3   \n",
       "CheXpert-v1.0/train/patient42720/study1/view1_f...                           3   \n",
       "\n",
       "                                                    CARDIOMEGALY  \\\n",
       "image_id                                                           \n",
       "CheXpert-v1.0/train/patient42720/study2/view1_f...             3   \n",
       "CheXpert-v1.0/train/patient42720/study7/view1_f...             0   \n",
       "CheXpert-v1.0/train/patient42720/study8/view1_f...             0   \n",
       "CheXpert-v1.0/train/patient42720/study6/view1_f...             3   \n",
       "CheXpert-v1.0/train/patient42720/study1/view1_f...             3   \n",
       "\n",
       "                                                    AIRSPACE_OPACITY  \\\n",
       "image_id                                                               \n",
       "CheXpert-v1.0/train/patient42720/study2/view1_f...                 3   \n",
       "CheXpert-v1.0/train/patient42720/study7/view1_f...                 1   \n",
       "CheXpert-v1.0/train/patient42720/study8/view1_f...                 1   \n",
       "CheXpert-v1.0/train/patient42720/study6/view1_f...                 3   \n",
       "CheXpert-v1.0/train/patient42720/study1/view1_f...                 3   \n",
       "\n",
       "                                                    LUNG_LESION  \\\n",
       "image_id                                                          \n",
       "CheXpert-v1.0/train/patient42720/study2/view1_f...            3   \n",
       "CheXpert-v1.0/train/patient42720/study7/view1_f...            3   \n",
       "CheXpert-v1.0/train/patient42720/study8/view1_f...            3   \n",
       "CheXpert-v1.0/train/patient42720/study6/view1_f...            3   \n",
       "CheXpert-v1.0/train/patient42720/study1/view1_f...            3   \n",
       "\n",
       "                                                    PULMONARY_EDEMA  \\\n",
       "image_id                                                              \n",
       "CheXpert-v1.0/train/patient42720/study2/view1_f...                1   \n",
       "CheXpert-v1.0/train/patient42720/study7/view1_f...                3   \n",
       "CheXpert-v1.0/train/patient42720/study8/view1_f...                3   \n",
       "CheXpert-v1.0/train/patient42720/study6/view1_f...                1   \n",
       "CheXpert-v1.0/train/patient42720/study1/view1_f...                1   \n",
       "\n",
       "                                                    CONSOLIDATION  PNEUMONIA  \\\n",
       "image_id                                                                       \n",
       "CheXpert-v1.0/train/patient42720/study2/view1_f...              3          3   \n",
       "CheXpert-v1.0/train/patient42720/study7/view1_f...              3          3   \n",
       "CheXpert-v1.0/train/patient42720/study8/view1_f...              3          3   \n",
       "CheXpert-v1.0/train/patient42720/study6/view1_f...              3          3   \n",
       "CheXpert-v1.0/train/patient42720/study1/view1_f...              3          3   \n",
       "\n",
       "                                                    ATELECTASIS  ...  \\\n",
       "image_id                                                         ...   \n",
       "CheXpert-v1.0/train/patient42720/study2/view1_f...            3  ...   \n",
       "CheXpert-v1.0/train/patient42720/study7/view1_f...            3  ...   \n",
       "CheXpert-v1.0/train/patient42720/study8/view1_f...            3  ...   \n",
       "CheXpert-v1.0/train/patient42720/study6/view1_f...            3  ...   \n",
       "CheXpert-v1.0/train/patient42720/study1/view1_f...            3  ...   \n",
       "\n",
       "                                                    EFFUSION  PLEURAL_OTHER  \\\n",
       "image_id                                                                      \n",
       "CheXpert-v1.0/train/patient42720/study2/view1_f...         1              3   \n",
       "CheXpert-v1.0/train/patient42720/study7/view1_f...         1              3   \n",
       "CheXpert-v1.0/train/patient42720/study8/view1_f...         1              3   \n",
       "CheXpert-v1.0/train/patient42720/study6/view1_f...         1              3   \n",
       "CheXpert-v1.0/train/patient42720/study1/view1_f...         1              3   \n",
       "\n",
       "                                                    FRACTURE  SUPPORT_DEVICES  \\\n",
       "image_id                                                                        \n",
       "CheXpert-v1.0/train/patient42720/study2/view1_f...         3                1   \n",
       "CheXpert-v1.0/train/patient42720/study7/view1_f...         3                1   \n",
       "CheXpert-v1.0/train/patient42720/study8/view1_f...         3                1   \n",
       "CheXpert-v1.0/train/patient42720/study6/view1_f...         3                1   \n",
       "CheXpert-v1.0/train/patient42720/study1/view1_f...         3                1   \n",
       "\n",
       "                                                      patient_id  split  \\\n",
       "image_id                                                                  \n",
       "CheXpert-v1.0/train/patient42720/study2/view1_f...  patient42720  train   \n",
       "CheXpert-v1.0/train/patient42720/study7/view1_f...  patient42720  train   \n",
       "CheXpert-v1.0/train/patient42720/study8/view1_f...  patient42720  train   \n",
       "CheXpert-v1.0/train/patient42720/study6/view1_f...  patient42720  train   \n",
       "CheXpert-v1.0/train/patient42720/study1/view1_f...  patient42720  train   \n",
       "\n",
       "                                                   GENDER AGE_AT_CXR  \\\n",
       "image_id                                                               \n",
       "CheXpert-v1.0/train/patient42720/study2/view1_f...   Male         58   \n",
       "CheXpert-v1.0/train/patient42720/study7/view1_f...   Male         58   \n",
       "CheXpert-v1.0/train/patient42720/study8/view1_f...   Male         58   \n",
       "CheXpert-v1.0/train/patient42720/study6/view1_f...   Male         58   \n",
       "CheXpert-v1.0/train/patient42720/study1/view1_f...   Male         58   \n",
       "\n",
       "                                                    PRIMARY_RACE  \\\n",
       "image_id                                                           \n",
       "CheXpert-v1.0/train/patient42720/study2/view1_f...         White   \n",
       "CheXpert-v1.0/train/patient42720/study7/view1_f...         White   \n",
       "CheXpert-v1.0/train/patient42720/study8/view1_f...         White   \n",
       "CheXpert-v1.0/train/patient42720/study6/view1_f...         White   \n",
       "CheXpert-v1.0/train/patient42720/study1/view1_f...         White   \n",
       "\n",
       "                                                                  ETHNICITY  \n",
       "image_id                                                                     \n",
       "CheXpert-v1.0/train/patient42720/study2/view1_f...  Non-Hispanic/Non-Latino  \n",
       "CheXpert-v1.0/train/patient42720/study7/view1_f...  Non-Hispanic/Non-Latino  \n",
       "CheXpert-v1.0/train/patient42720/study8/view1_f...  Non-Hispanic/Non-Latino  \n",
       "CheXpert-v1.0/train/patient42720/study6/view1_f...  Non-Hispanic/Non-Latino  \n",
       "CheXpert-v1.0/train/patient42720/study1/view1_f...  Non-Hispanic/Non-Latino  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190499"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint the embeddings with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datastore = np.load(root / \"embeddings.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(root, max_rows=0):\n",
    "    labels = pd.read_csv(root / \"labels.csv\", index_col=\"image_id\")\n",
    "\n",
    "    # Extract subset of rows for which all labels are available\n",
    "    labels = labels.loc[labels[\"PNEUMONIA\"].isin({1, 3})]\n",
    "    labels = labels.loc[labels[\"EFFUSION\"].isin({1, 3})]\n",
    "    labels = labels.loc[labels[\"GENDER\"] != \"Unknown\"]\n",
    "\n",
    "    if max_rows == 0:\n",
    "        max_rows = len(labels)\n",
    "\n",
    "    columns = [\"PNEUMONIA\", \"EFFUSION\", \"GENDER\"]\n",
    "    for t in columns:\n",
    "        code, uniques = pd.factorize(labels[t], sort=True)\n",
    "        print(t, code, uniques) #1->0, 3->1, female->0, male->1\n",
    "        labels[t] = code\n",
    "    \n",
    "    m = np.median(labels[\"AGE_AT_CXR\"])\n",
    "    print('median age ', m)\n",
    "    labels[\"AGE_QUANTIZED\"] = (labels[\"AGE_AT_CXR\"] > m)\n",
    "    columns.append(\"AGE_QUANTIZED\")\n",
    "\n",
    "    YZ = labels[columns].to_numpy()\n",
    "    YZ = YZ[:max_rows]\n",
    "    return YZ, labels, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNEUMONIA [1 1 1 ... 0 0 0] Int64Index([1, 3], dtype='int64')\n",
      "EFFUSION [0 0 0 ... 0 0 0] Int64Index([1, 3], dtype='int64')\n",
      "GENDER [1 1 1 ... 1 0 0] Index(['Female', 'Male'], dtype='object')\n",
      "median age  62.0\n",
      "(139907, 4)\n"
     ]
    }
   ],
   "source": [
    "YZ, labels, columns = extract_labels(root, max_rows=0)\n",
    "print(YZ.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(YZ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(root, labels, max_rows=20):\n",
    "    datastore = np.load(root / \"embeddings.npz\")\n",
    "    if max_rows == 0:\n",
    "        max_rows = len(labels)\n",
    "    ndims = 1376\n",
    "    X = np.zeros((max_rows, ndims))\n",
    "    i = 0\n",
    "    for fname in labels.index:\n",
    "        x = datastore[fname]\n",
    "        i += 1\n",
    "        if i >= max_rows: break\n",
    "        X[i,:] = x\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139907, 1376)\n",
      "CPU times: user 15min 47s, sys: 4.41 s, total: 15min 51s\n",
      "Wall time: 15min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = extract_features(root, labels, max_rows=0)\n",
    "print(X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PNEUMONIA', 'EFFUSION', 'GENDER', 'AGE_QUANTIZED']\n"
     ]
    }
   ],
   "source": [
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(root / 'data_matrix.npz', X=X, YZ=YZ, columns=columns)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-computed data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'YZ', 'columns']\n",
      "(139907, 1376)\n",
      "(139907, 4)\n",
      "['PNEUMONIA' 'EFFUSION' 'GENDER' 'AGE_QUANTIZED']\n"
     ]
    }
   ],
   "source": [
    "data = np.load(root / 'data_matrix.npz', allow_pickle=True)\n",
    "print(data.files)\n",
    "print(data['X'].shape)\n",
    "print(data['YZ'].shape)\n",
    "print(data['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "ndx = np.where(data['columns'] == 'EFFUSION')[0][0]\n",
    "print(ndx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = data['X']\n",
    "ndx = np.where(data['columns'] == 'EFFUSION')[0][0]\n",
    "Ytrain = data['YZ'][:,ndx]\n",
    "\n",
    "classifier = Pipeline([\n",
    "        ('standardscaler', StandardScaler()),\n",
    "        #('poly', PolynomialFeatures(degree=2)), \n",
    "        ('logreg', LogisticRegression(random_state=0, max_iter=500, C=10, solver='sag', multi_class='multinomial'))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 0\n",
      " 0 0 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1\n",
      " 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "(139907, 1376)\n",
      "(139907,)\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(Ytrain))\n",
    "print(Ytrain[:100])\n",
    "\n",
    "print(Xtrain.shape)\n",
    "print(Ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'unknown'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/sklearn/pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    381\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 382\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1146\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[1;32m   1138\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m   1139\u001b[0m     X,\n\u001b[1;32m   1140\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39msolver \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msag\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msaga\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1145\u001b[0m )\n\u001b[0;32m-> 1146\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n\u001b[1;32m   1149\u001b[0m multi_class \u001b[39m=\u001b[39m _check_multi_class(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmulti_class, solver, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_))\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/sklearn/utils/multiclass.py:200\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    192\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[1;32m    194\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    195\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    199\u001b[0m ]:\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'unknown'"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "classifier.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the datasets for each domain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"/home/kpmurphy/data/CheXpert\")\n",
    "dataset_y_column = \"EFFUSION\"\n",
    "dataset_z_column = \"GENDER\"\n",
    "dataset_use_embedding = True\n",
    "train_domains_set = [9]\n",
    "target_domain_count = 512\n",
    "\n",
    "import random\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "key = jax.random.PRNGKey(seed)\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "\n",
    "dataset = MultipleDomainCheXpert(root, generator, dataset_y_column, dataset_z_column, dataset_use_embedding, train_domains_set, target_domain_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e1aafb1a5b8a6c5cc9d9564fe8ce376ad7cec1976d94f450e8b79a35770c931"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
